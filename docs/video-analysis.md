# 動画分析機能 - ユーザー録画と評価

セッション中の受講生をカメラで撮影・録画し、Amazon Bedrockの視覚系AIモデル（Nova）を活用して、視線、表情、身振り、感情表現などを数値化して評価する機能です。

## 機能概要

1. セッション中に受講生をWebカメラで録画
2. 録画データをAmazon S3に安全に保存
3. Amazon Bedrock Novaによる動画分析
4. 分析結果を視覚化して表示（1-10点のスコアリング）
5. 長所・改善点の提示（自然言語による説明）

## 使用方法

### 録画方法

1. セッション画面で「カメラを起動」ボタンをクリックします
2. カメラへのアクセス許可を求められたら「許可」をクリックします
3. 「録画開始」ボタンをクリックして録画を開始します
4. 録画中は右上に赤い「REC」マークと経過時間が表示されます
5. 「録画停止」ボタンをクリックして録画を終了します
6. 「アップロード」ボタンをクリックして録画データをアップロードします

### 分析結果の確認

1. セッション終了後、結果画面の「表情・身振り分析」タブをクリックします
2. 各評価項目（視線、表情、身振り、感情表現）のスコアが表示されます
3. 「強み」「改善点」セクションで具体的なフィードバックを確認できます
4. 「詳細分析」セクションでは総合的な評価コメントを読むことができます

## 分析評価項目

1. **視線（Eye Contact）**
   - アイコンタクトの質と頻度を1-10点で評価
   - 聞き手との視線の合わせ方、目線の動きなどを分析

2. **表情（Facial Expression）**
   - 表情の豊かさと適切さを1-10点で評価
   - 話の内容に合った表情変化、表情の多様性などを分析

3. **身振り（Gesture）**
   - 手や体の動きの自然さと効果を1-10点で評価
   - 説明時の手振り、姿勢、体の向きなどを分析

4. **感情表現（Emotion）**
   - 話の内容に合った感情表現の適切さを1-10点で評価
   - 声のトーン、表情と声の一致度などを分析

## 技術仕様

### フロントエンド

- **録画機能**: Webブラウザの`MediaRecorder` APIを使用
- **動画形式**: WebM形式（vp9, opusコーデック）
- **アップロード**: 署名付きURLによる直接S3アップロード
- **UI/UX**: Material-UIを使用した録画インターフェース

### バックエンド

- **ストレージ**: Amazon S3（サーバーサイド暗号化、署名付きURL）
- **分析エンジン**: Amazon Bedrock Nova API
- **データ保存**: DynamoDB（既存のSessionFeedbackテーブルを拡張）
- **API**: API Gateway + Lambda関数

### セキュリティ考慮事項

- 動画データはS3内でサーバーサイド暗号化
- 署名付きURLによる安全なアップロード（有効期限10分）
- バケットポリシーによる厳格なアクセス制御
- 未使用の録画データは14日後に自動削除

## 将来の拡張可能性

- リアルタイム表情分析によるフィードバック
- ヒートマップや時系列での視線・表情変化の可視化
- 複数セッションの時系列比較によるスキル向上の追跡
- VRトレーニング環境との統合